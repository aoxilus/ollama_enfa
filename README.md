# Ollama Desktop Cursor AI

> **Developed by aoxilus** to connect local Ollama AI with Cursor AI and development tools. Complete integration between SDKs and terminal for local Ollama usage with GPU optimization.

---

# Ollama Desktop Cursor AI

> **Desarrollado por aoxilus** para conectar Ollama AI local con Cursor AI y herramientas de desarrollo. IntegraciÃ³n completa entre SDKs y terminal para uso local de Ollama con optimizaciÃ³n GPU.

---

## ðŸš€ Current Status - Optimized / Estado Actual - Optimizado

### âœ… **Implemented Improvements / Mejoras Implementadas:**
- **GPU Acceleration**: 100% GPU utilization with codellama:7b-code-q4_K_M
- **Fast Responses**: 669ms for simple questions, 3.4s for code
- **Automatic Validation**: Response quality verification
- **Optimized Prompts**: Enhanced structure for different query types
- **Adjusted Parameters**: Temperature and tokens optimized by question type
- **Cursor AI Timeout**: Automatic timeout configuration to prevent hanging

### ðŸŽ¯ **Main Model / Modelo Principal:**
- **Model**: `codellama:7b-code-q4_K_M`
- **GPU**: 100% utilization
- **Speed**: Responses in <1s for simple questions
- **Quality**: Coherent and precise responses

---

## What is this project? / Â¿QuÃ© es este proyecto?

This project is an **intelligent integration** between Ollama (local AI) and Cursor AI (code editor) that enables:

Este proyecto es una **integraciÃ³n inteligente** entre Ollama (IA local) y Cursor AI (editor de cÃ³digo) que permite:

- ðŸ”— **Direct connection** between your editor and local AI models
- ðŸ“ **Automatic context analysis** of your project
- ðŸ’¾ **Smart cache** for fast responses
- ðŸ› ï¸ **Enhanced development tools** with local AI
- ðŸ”„ **Configurable sync/async mode**
- ðŸš€ **GPU optimization** for maximum speed
- âœ… **Automatic response validation**
- â±ï¸ **Timeout protection** for Cursor AI terminal

---

## Why was it developed? / Â¿Por quÃ© se desarrollÃ³?

- **Privacy**: Use local AI without sending code to external servers
- **Speed**: Instant responses without network latency
- **Context**: Deep analysis of your specific project
- **Flexibility**: Works with any Ollama model
- **Integration**: Connects with Cursor AI and other editors
- **GPU**: Leverages your hardware for maximum speed
- **Reliability**: Prevents terminal hanging with automatic timeouts

---

## Quick Usage - Optimized / Uso RÃ¡pido - Optimizado

### ðŸš€ Fast Test (Recommended) / Test RÃ¡pido (Recomendado)
```bash
# Simple questions - 669ms / Preguntas simples - 669ms
python tests/test_fast.py codellama:7b-code-q4_K_M "What is 2+2?"

# Code - 3.4s / CÃ³digo - 3.4s
python tests/test_code.py codellama:7b-code-q4_K_M "Write a Python function to calculate factorial"
```

### Complete Python / Python Completo
```bash
python python/ollama_simple_async.py "What is 2+2"
python python/ollama_simple_async.py "Write a Python function to solve matrices in echelon form"
```

### Optimized PowerShell / PowerShell Optimizado
```powershell
# Fast test (sub-second) / Test rÃ¡pido (sub-segundo)
.\tests\test_fast.ps1 "codellama:7b-code-q4_K_M" "What is 2+2?"

# Code generation / GeneraciÃ³n de cÃ³digo
.\tests\test_code.ps1 "codellama:7b-code-q4_K_M" "Write a Python function to calculate factorial"

# General test / Test general
.\tests\test_clean.ps1 "codellama:7b-code-q4_K_M" "What is the capital of France?"

# Real-time monitoring / Monitoreo en tiempo real
.\powershell\monitor_ollama.ps1 5

# Complete setup / ConfiguraciÃ³n completa
.\powershell\setup_ollama.ps1
```

---

## Cursor AI Configuration / ConfiguraciÃ³n de Cursor AI

### â±ï¸ **Automatic Timeout Protection**
The project includes automatic timeout configuration for Cursor AI to prevent terminal hanging:

El proyecto incluye configuraciÃ³n automÃ¡tica de timeout para Cursor AI para prevenir colgamientos:

```json
// .vscode/settings.json
{
  "terminal.integrated.defaultProfile.windows": "PowerShell",
  "terminal.integrated.profiles.windows": {
    "PowerShell": {
      "source": "PowerShell",
      "args": [
        "-NoExit",
        "-Command",
        "& { $env:PSDefaultParameterValues = 'Invoke-RestMethod:TimeoutSec=30'; $env:TERMINAL_TIMEOUT = '30'; Write-Host 'ðŸš€ Terminal con timeout configurado' -ForegroundColor Green }"
      ],
      "env": {
        "PSDefaultParameterValues": "Invoke-RestMethod:TimeoutSec=30",
        "TERMINAL_TIMEOUT": "30"
      }
    }
  }
}
```

### ðŸŽ¯ **Features:**
- **30-second timeout** for all commands
- **Automatic process cleanup** for hanging jobs
- **PowerShell optimization** for better performance
- **No more terminal hanging** in Cursor AI

---

## Project Structure / Estructura del Proyecto

```
ollama_desktop_cursorAI/
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json          # Cursor AI timeout configuration
â”œâ”€â”€ python/                    # Python scripts and modules
â”‚   â”œâ”€â”€ ollama_simple_async.py # Main async client
â”‚   â”œâ”€â”€ ollama_cache.py        # Caching system
â”‚   â”œâ”€â”€ ollama_errors.py       # Error handling
â”‚   â”œâ”€â”€ monitor_ollama.py      # Real-time monitoring
â”‚   â”œâ”€â”€ optimize_ollama.py     # Performance optimization
â”‚   â””â”€â”€ benchmark_ollama.py    # Performance benchmarking
â”œâ”€â”€ powershell/                # PowerShell scripts
â”‚   â”œâ”€â”€ ollama_simple_async.ps1 # Main PowerShell client
â”‚   â”œâ”€â”€ monitor_ollama.ps1     # Real-time monitoring
â”‚   â”œâ”€â”€ setup_ollama.ps1       # Setup and configuration
â”‚   â””â”€â”€ optimize_ollama.ps1    # Performance optimization
â”œâ”€â”€ tests/                     # Test scripts
â”‚   â”œâ”€â”€ test_fast.py          # Fast tests (669ms)
â”‚   â”œâ”€â”€ test_code.py          # Code generation tests (3.4s)
â”‚   â”œâ”€â”€ test_clean.py         # General tests
â”‚   â””â”€â”€ test_fast.ps1         # PowerShell fast tests
â”œâ”€â”€ .cursorrules              # Cursor AI configuration
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ LICENSE                   # Project license
```

---

## Performance Metrics / MÃ©tricas de Rendimiento

### âš¡ **Speed Tests:**
- **Simple Questions**: 669ms average
- **Code Generation**: 3.4s average
- **GPU Utilization**: 100%
- **Memory Usage**: Optimized
- **Response Quality**: High accuracy

### ðŸŽ¯ **Optimized Parameters:**
- **Temperature Fast**: 0.1 (precise answers)
- **Temperature Code**: 0.2 (balanced creativity)
- **Temperature General**: 0.7 (creative responses)
- **Tokens Fast**: 20 (quick responses)
- **Tokens Normal**: 100 (standard responses)
- **Tokens Code**: 200 (detailed code)

---

## Installation / InstalaciÃ³n

### Prerequisites / Prerrequisitos:
- **Ollama** installed and running
- **Python 3.8+** with required packages
- **PowerShell 5.1+** (Windows)
- **Cursor AI** for editor integration

### Setup / ConfiguraciÃ³n:
1. **Clone repository** / Clonar repositorio
2. **Install dependencies** / Instalar dependencias: `pip install -r python/requirements.txt`
3. **Configure Cursor AI** / Configurar Cursor AI: Copy `.vscode/settings.json` to your workspace
4. **Test connection** / Probar conexiÃ³n: `python tests/test_fast.py`

---

## Usage Examples / Ejemplos de Uso

### Quick Questions / Preguntas RÃ¡pidas
```bash
# Python
python tests/test_fast.py codellama:7b-code-q4_K_M "What is 2+2?"

# PowerShell
.\tests\test_fast.ps1 "codellama:7b-code-q4_K_M" "What is 2+2?"
```

### Code Generation / GeneraciÃ³n de CÃ³digo
```bash
# Python
python tests/test_code.py codellama:7b-code-q4_K_M "Create a JavaScript calculator"

# PowerShell
.\tests\test_code.ps1 "codellama:7b-code-q4_K_M" "Create a JavaScript calculator"
```

### Monitoring / Monitoreo
```bash
# Real-time monitoring
.\powershell\monitor_ollama.ps1 5

# Performance optimization
python python/optimize_ollama.py
```

---

## Troubleshooting / SoluciÃ³n de Problemas

### Common Issues / Problemas Comunes:

#### **Cursor AI Terminal Hanging**
- **Solution**: The `.vscode/settings.json` configuration automatically prevents this
- **Manual fix**: Use `.\tests\test_clean.ps1` for cleanup

#### **Slow Responses**
- **Solution**: Check GPU utilization with `.\powershell\monitor_ollama.ps1`
- **Optimization**: Run `python python/optimize_ollama.py`

#### **Connection Errors**
- **Solution**: Ensure Ollama is running on `http://localhost:11434`
- **Test**: Use `python tests/test_fast.py` to verify connection

---

## Contributing / Contribuir

1. **Fork** the repository
2. **Create** a feature branch
3. **Make** your changes
4. **Test** with the provided test scripts
5. **Submit** a pull request

---

## License / Licencia

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## Status / Estado

**âœ… Project Status**: Complete and Optimized
**âœ… Cursor AI Integration**: Working with timeout protection
**âœ… Performance**: Optimized for speed and reliability
**âœ… Documentation**: Complete bilingual documentation

**Ãšltima actualizaciÃ³n**: $(Get-Date)
**VersiÃ³n**: 2.0 - Cursor AI Timeout Integration
