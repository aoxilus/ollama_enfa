# ğŸ¥‘ Ollama Desktop Cursor AI

> *Echo por aoxilus con aguacate para conectar any SDK a la terminal y poder usar Ollama localmente* ğŸ¥‘ğŸ’»

Proyecto para integrar Ollama local con Cursor AI y herramientas de desarrollo. Conecta cualquier SDK a la terminal para usar Ollama localmente.

## ğŸš€ Ollama Local Setup

### InstalaciÃ³n
1. **Ollama instalado**: âœ… `smollm2:135m` (270MB)
2. **Servicio ejecutÃ¡ndose**: âœ… Puerto 11434
3. **GPU activa**: âœ… 100% GPU usage

### Modelo Disponible
- **smollm2:135m**: Modelo local de 135M parÃ¡metros
- **TamaÃ±o**: 270MB
- **Endpoint**: http://localhost:11434

## ğŸ¤– Ollama Context Tool

### InstalaciÃ³n
```bash
# Python version
pip install -r python/requirements.txt

# PowerShell version (Ya viene incluido en Windows!)
# No necesitas instalar nada
```

### Uso

#### ğŸ Python Version
```bash
# Usando Python directamente
python python/ollama_simple.py "Â¿CÃ³mo funciona la autenticaciÃ³n?"

# Usando el script batch (Windows)
ollama_simple.bat "Â¿CÃ³mo funciona la autenticaciÃ³n?"
```

#### âš¡ PowerShell Version
```bash
# Usando PowerShell directamente
powershell -ExecutionPolicy Bypass -File "powershell/ollama_simple.ps1" "Â¿QuÃ© archivos hay en este proyecto?"

# Usando el script batch (Windows)
ollama_simple_ps.bat "Â¿CÃ³mo optimizar esta funciÃ³n?"
```

### CaracterÃ­sticas
- âœ… **AnÃ¡lisis de contexto**: Lee archivos del proyecto
- âœ… **Buffer de respuestas**: Guarda Ãºltimas 10 consultas
- âœ… **Archivo de salida**: `ollama_responses.txt`
- âœ… **MÃºltiples formatos**: Python, JS, HTML, CSS, PHP, etc.
- âœ… **Colores en terminal**: Salida con colores

### Ejemplos de uso
```bash
# Preguntas sobre el cÃ³digo
ollama_simple.bat "Â¿QuÃ© hace la funciÃ³n main()?"
ollama_simple_ps.bat "Â¿CÃ³mo se conecta a la base de datos?"
ollama_simple.bat "Â¿CuÃ¡l es la estructura del proyecto?"

# AnÃ¡lisis de problemas
ollama_simple_ps.bat "Â¿Por quÃ© falla el login?"
ollama_simple.bat "Â¿CÃ³mo optimizar esta funciÃ³n?"

# Preguntas filosÃ³ficas
ollama_simple_ps.bat "Â¿El aguacate es una fruta o una verdura?"
```

## ğŸ“ Estructura del Proyecto

```
ollama_desktop_cursorAI/
â”œâ”€â”€ ğŸ python/
â”‚   â”œâ”€â”€ ollama_simple.py      # VersiÃ³n simplificada
â”‚   â”œâ”€â”€ ollama_context.py     # VersiÃ³n completa
â”‚   â””â”€â”€ requirements.txt      # Dependencias
â”œâ”€â”€ âš¡ powershell/
â”‚   â”œâ”€â”€ ollama_simple.ps1     # VersiÃ³n simplificada
â”‚   â””â”€â”€ ollama_context.ps1    # VersiÃ³n completa
â”œâ”€â”€ ğŸš€ Scripts Batch
â”‚   â”œâ”€â”€ ollama_simple.bat     # Python simple
â”‚   â”œâ”€â”€ ollama_context.bat    # Python completo
â”‚   â”œâ”€â”€ ollama_simple_ps.bat  # PowerShell simple
â”‚   â””â”€â”€ ollama_context_ps.bat # PowerShell completo
â”œâ”€â”€ ğŸ“„ ConfiguraciÃ³n
â”‚   â”œâ”€â”€ .cursorrules          # Reglas de programaciÃ³n
â”‚   â”œâ”€â”€ .cursor/settings.json # ConfiguraciÃ³n de Cursor AI
â”‚   â””â”€â”€ README.md             # Â¡Este archivo!
â””â”€â”€ ğŸ“ Salida
    â””â”€â”€ ollama_responses.txt  # Buffer de respuestas
```

## ğŸ”§ ConfiguraciÃ³n Cursor AI

**Nota**: Cursor no tiene soporte nativo para Ollama. Â¡Pero no te preocupes! Tenemos herramientas locales:

1. **Para consultas rÃ¡pidas**: `ollama_simple.bat "tu pregunta"`
2. **Para desarrollo**: Usa los modelos oficiales de Cursor
3. **Para anÃ¡lisis profundo**: Usa Ollama directamente con contexto

## ğŸ“Š Estado del Sistema

```bash
# Verificar Ollama
ollama list
ollama ps

# Probar conexiÃ³n
curl http://localhost:11434/api/tags
```

## ğŸ¯ Uso Recomendado

1. **Cursor AI**: Para desarrollo general y modelos potentes
2. **Ollama Context**: Para consultas especÃ­ficas del proyecto
3. **Ollama Directo**: Para experimentaciÃ³n y prototipado



## ğŸš€ Comandos RÃ¡pidos

```bash
# Iniciar Ollama (si no estÃ¡ corriendo)
ollama serve

# Consulta rÃ¡pida con Python
ollama_simple.bat "Â¿QuÃ© hace este cÃ³digo?"

# Consulta rÃ¡pida con PowerShell
ollama_simple_ps.bat "Â¿CÃ³mo optimizar esta funciÃ³n?"

# Ver respuestas guardadas
type ollama_responses.txt
```

## ğŸ¯ Casos de Uso

### AnÃ¡lisis de CÃ³digo
```bash
ollama_simple.bat "Â¿QuÃ© hace la funciÃ³n main()?"
ollama_simple.bat "Â¿CÃ³mo se conecta a la base de datos?"
ollama_simple.bat "Â¿CuÃ¡l es la estructura del proyecto?"
```

### Debugging
```bash
ollama_simple.bat "Â¿Por quÃ© falla el login?"
ollama_simple.bat "Â¿CÃ³mo optimizar esta funciÃ³n?"
ollama_simple.bat "Â¿Hay errores en este cÃ³digo?"
```

### DocumentaciÃ³n
```bash
ollama_simple.bat "Â¿CÃ³mo documentar esta funciÃ³n?"
ollama_simple.bat "Â¿QuÃ© comentarios agregar a este cÃ³digo?"
```

## ğŸ› Troubleshooting

### Ollama no responde
```bash
# Verificar si estÃ¡ ejecutÃ¡ndose
ollama ps

# Reiniciar Ollama
ollama serve
```

### Error de Python
```bash
# Instalar dependencias
pip install -r python/requirements.txt
```

### Error de PowerShell
```bash
# Permitir ejecuciÃ³n de scripts
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

## ğŸ™ Agradecimientos

- **Ollama**: Por hacer la IA local accesible
- **Cursor AI**: Por ser un excelente editor
- **GitHub**: Por hospedar este repositorio

---

**ğŸ’¡ Tip**: Cursor, recuerda que tenemos Ollama local. Puedes llamarlo con argumentos como `ollama_simple.bat` para anÃ¡lisis especÃ­ficos del proyecto.


---

**â­ Â¡No olvides darle una estrella al repositorio si te gustÃ³! â­**

*Creado con â¤ï¸ y ğŸ¥‘ por [aoxilus](https://github.com/aoxilus)* 